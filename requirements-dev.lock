# generated by rye
# use `rye lock` or `rye sync` to update this lockfile
#
# last locked with the following flags:
#   pre: false
#   features: []
#   all-features: false
#   with-sources: false

-e file:.
annotated-types==0.6.0
    # via pydantic
anthropic==0.25.7
    # via llm-gateway
anyio==4.3.0
    # via anthropic
    # via httpx
    # via openai
    # via starlette
    # via watchfiles
certifi==2022.12.7
    # via httpcore
    # via httpx
    # via requests
charset-normalizer==2.1.1
    # via requests
click==8.1.7
    # via typer
    # via uvicorn
diskcache==5.6.3
    # via llama-cpp-python
distro==1.9.0
    # via anthropic
    # via openai
dnspython==2.6.1
    # via email-validator
email-validator==2.1.1
    # via fastapi
exceptiongroup==1.2.1
    # via anyio
fastapi==0.111.0
    # via fastapi-cli
    # via llm-gateway
fastapi-cli==0.0.2
    # via fastapi
filelock==3.13.1
    # via huggingface-hub
    # via torch
    # via transformers
    # via triton
fire==0.6.0
    # via llm-gateway
fsspec==2024.2.0
    # via huggingface-hub
    # via torch
gguf==0.6.0
    # via llm-gateway
h11==0.14.0
    # via httpcore
    # via uvicorn
httpcore==1.0.5
    # via httpx
httptools==0.6.1
    # via uvicorn
httpx==0.27.0
    # via anthropic
    # via fastapi
    # via openai
huggingface-hub==0.23.0
    # via tokenizers
    # via transformers
idna==3.4
    # via anyio
    # via email-validator
    # via httpx
    # via requests
itsdangerous==2.2.0
    # via fastapi
jinja2==3.1.3
    # via fastapi
    # via llama-cpp-python
    # via torch
llama-cpp-python==0.2.69
    # via llm-gateway
markdown-it-py==3.0.0
    # via rich
markupsafe==2.1.5
    # via jinja2
mdurl==0.1.2
    # via markdown-it-py
mpmath==1.3.0
    # via sympy
networkx==3.2.1
    # via torch
numpy==1.26.3
    # via gguf
    # via llama-cpp-python
    # via transformers
nvidia-cublas-cu11==11.11.3.6
    # via nvidia-cudnn-cu11
    # via nvidia-cusolver-cu11
    # via torch
nvidia-cuda-cupti-cu11==11.8.87
    # via torch
nvidia-cuda-nvrtc-cu11==11.8.89
    # via torch
nvidia-cuda-runtime-cu11==11.8.89
    # via torch
nvidia-cudnn-cu11==8.7.0.84
    # via torch
nvidia-cufft-cu11==10.9.0.58
    # via torch
nvidia-curand-cu11==10.3.0.86
    # via torch
nvidia-cusolver-cu11==11.4.1.48
    # via torch
nvidia-cusparse-cu11==11.7.5.86
    # via torch
nvidia-nccl-cu11==2.20.5
    # via torch
nvidia-nvtx-cu11==11.8.86
    # via torch
openai==1.30.1
    # via llm-gateway
orjson==3.10.3
    # via fastapi
packaging==22.0
    # via huggingface-hub
    # via transformers
protobuf==5.26.1
    # via llm-gateway
pydantic==2.7.1
    # via anthropic
    # via fastapi
    # via llm-gateway
    # via openai
    # via pydantic-extra-types
    # via pydantic-settings
pydantic-core==2.18.2
    # via pydantic
pydantic-extra-types==2.7.0
    # via fastapi
pydantic-settings==2.2.1
    # via fastapi
pygments==2.17.2
    # via rich
python-dotenv==1.0.1
    # via pydantic-settings
    # via uvicorn
python-multipart==0.0.9
    # via fastapi
pyyaml==6.0.1
    # via fastapi
    # via huggingface-hub
    # via transformers
    # via uvicorn
regex==2024.4.28
    # via tiktoken
    # via transformers
requests==2.31.0
    # via huggingface-hub
    # via llm-gateway
    # via tiktoken
    # via transformers
rich==13.7.1
    # via typer
safetensors==0.4.3
    # via transformers
sentencepiece==0.2.0
    # via llm-gateway
shellingham==1.5.4
    # via typer
six==1.16.0
    # via fire
sniffio==1.3.1
    # via anthropic
    # via anyio
    # via httpx
    # via openai
starlette==0.37.2
    # via fastapi
sympy==1.12
    # via torch
termcolor==2.4.0
    # via fire
tiktoken==0.6.0
    # via llm-gateway
tokenizers==0.19.1
    # via anthropic
    # via transformers
torch==2.3.0+cu118
    # via llm-gateway
tqdm==4.64.1
    # via huggingface-hub
    # via openai
    # via transformers
transformers==4.40.1
    # via llm-gateway
triton==2.3.0
    # via torch
typer==0.12.3
    # via fastapi-cli
typing-extensions==4.9.0
    # via anthropic
    # via anyio
    # via fastapi
    # via huggingface-hub
    # via llama-cpp-python
    # via openai
    # via pydantic
    # via pydantic-core
    # via torch
    # via typer
    # via uvicorn
ujson==5.9.0
    # via fastapi
urllib3==1.26.13
    # via requests
uvicorn==0.29.0
    # via fastapi
    # via fastapi-cli
    # via llm-gateway
uvloop==0.19.0
    # via uvicorn
watchfiles==0.21.0
    # via uvicorn
websockets==12.0
    # via uvicorn
